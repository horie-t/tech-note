---
title: "Suiの再設計をLLMに再度、評価してもらう"
emoji: "🔖"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["llm"]
published: true
---

## 愚かな人類にはプログラミング言語は不要って事？

https://x.com/t_honda/status/1996506501142163917

って事で現れたプログラミング言語「Sui」ですが、あっという間に「[LLMにやさしい言語SuiはLLMにやさしくなさそう](https://nowokay.hatenablog.com/entry/2025/12/12/063351)」と本質を見抜かれてしまいました。

それを受けて作者が「[LLMにやさしい言語SuiはLLMにやさしくなれそう](https://note.com/t_honda/n/n7822eccdfca1)」と方向を修正したようです。

LLMの事はLLMに聞くのが一番なので、GeminiにSuiの設計の方向の変更を評価してもらいましょう。以下のようにGeminiに質問しました。

```plaintext
プログラミング言語 [Sui](https://github.com/TakatoHonda/sui-lang) が以下のとおり批評されました。
* [LLMにやさしい言語SuiはLLMにやさしくなさそう](https://nowokay.hatenablog.com/entry/2025/12/12/063351)

それを受けて、以下のように方針変更したそうです。
* [LLMにやさしい言語SuiはLLMにやさしくなれそう](https://note.com/t_honda/n/n7822eccdfca1)

この変更によってプログラミング言語として役に立つものになりそうでしょうか？
* 忖度、配慮はせず冷静にお願いします
* 設計方針として正しいと思う所、正しくないと思う所を理由込みでまとめてください
* 特に「セマンティクス（意味）とシンタックス（表記）を分離した表現」はLLMにとって有益どうかについて、どんな点でメリット・デメリットがあるかを挙げてください。
```

Geminiからの回答全文を以下に示します。こんなに的確な分析を2, 3分で出してくるのだから、疑問に思ったらひとまずLLMに聞いてみるのが良いですね。Suiの設計者もLLMを相手に壁打ちをしてもらった方がいいかもしれません。

---

# **AIネイティブプログラミング言語の構造的進化：Suiの設計転換に関する批判的分析と展望**

## **エグゼクティブサマリー**

大規模言語モデル（LLM）とソフトウェアエンジニアリングの交差点は、プログラミング言語設計における根本的な再評価を促している。人間の認知と手動入力のために設計された従来の言語は、確率的なコード生成モデルにとって非効率な制約を課すものと見なされるようになりつつある。この文脈において、プログラミング言語 **Sui** は当初、「ゼロ・シンタックスエラー（Zero Syntax Errors）」と「ゼロ・タイポ（Zero Typos）」を掲げ、徹底的なトークン効率化と記号化を追求する設計で登場した。しかし、この初期設計は、LLMの推論能力に対する根本的な誤解に基づいているという批判に直面した。その批判とは、「トークン効率に最適化された言語が、必ずしもLLMの理解や推論に最適化されているわけではない」という逆説的な事実である。

本レポートは、この批判を受けてSuiが提示した「トークン効率重視の記号的言語」から「セマンティクス（意味）を重視した中間表現（IR）エコシステム」への戦略的ピボット（方針転換）について、専門的な視点から徹底的かつ網羅的に分析を行うものである。特に、Suiの新たな設計哲学の中核を成す「\*\*セマンティクス（意味）**と**シンタックス（表記）\*\*の分離」という概念が、生成AIの安定性と信頼性に寄与するメカニズムを解剖する。

分析の結果、Suiのピボットは、初期設計が抱えていた「意味論的不透明性」という致命的な欠陥を解消する上で理論的に正しい方向転換であると結論付ける。しかし、新たな「S-Plan」アーキテクチャの成功は、LLMがPythonのような膨大な事前学習データを持たない新規の構造化フォーマットを、いかにして「コンパイラの壁（Compiler Barrier）」を越えて確実に生成できるかという点に依存している。

本稿では、セマンティクスとシンタックスの分離が、次世代の「自律的エージェント（Agentic）」コーディングシステムにとって不可欠な要素であることを論証する。同時に、Suiが実用的な言語として定着するためには、単なるトークン削減ツールではなく、LLMの確率的な挙動を制約し、\*\*決定論的な検証可能性（Deterministic Verifiability）\*\*を提供するインフラストラクチャとしての地位を確立する必要があることを、厳密な根拠とともに提示する。


**1\. 序論：LLMフレンドリー設計の危機と転換**

### **1.1 背景：生成AI時代における言語設計のパラダイムシフト**

プログラミング言語の歴史は、抽象化の歴史であった。機械語からアセンブリ、C言語、そしてPythonへと至る進化は、人間の認知負荷を下げることを主眼としてきた。しかし、コードの書き手が「人間」から「LLM」へと移行しつつある現在、言語設計の最適化関数は劇的に変化している。LLMは疲労を知らず、膨大なボイラープレート（定型コード）を一瞬で生成できる一方で、コンテキストの喪失や論理的な幻覚（ハルシネーション）という人間とは異なる弱点を持つ。

この新しいパラダイムの中で登場した **Sui** は、当初「AIのための言語」として、極限までのトークン削減を目指した。変数名を v0, v1 といった連番に固定し、制御構造を簡素化することで、LLMの出力コストを下げ、構文エラーを構造的に排除しようと試みた1。しかし、このアプローチは、「LLMにやさしい言語SuiはLLMにやさしくなさそう」という批判2によって、その根本的な欠陥を指摘されることとなった。

### **1.2 批判の本質：圧縮と理解のトレードオフ**

批判の核心は、LLMの認知アーキテクチャ（Transformer）の特性にある。Transformerは、トークン間の統計的な相関関係（Attention）に基づいて次のトークンを予測する。このプロセスにおいて、変数名や関数名は単なる記号ではなく、意味論的なアンカー（碇）として機能する。例えば、user\_balance という変数名は、その変数が「数値」であり、「負になってはいけない」可能性が高く、「通貨に関連する操作」が行われるであろうという膨大なコンテキスト情報をLLMに提供する。

対して、Suiの初期設計が採用した v0 という無機質な識別子は、この意味論的リンクを切断するものであった。トークン数（表記の長さ）は減るが、文脈を維持するための推論コスト（内部的な計算資源）は逆に増大する。つまり、「物理的なトークン効率」を追求するあまり、「認知的な推論効率」を犠牲にしていたのである。これは、LLMを「コンパイラ」ではなく「読者」として扱うべきだという洞察の欠如に起因していた。

### **1.3 ピボットの概要：検証可能性への舵切り**

この批判を受けたSuiの開発チームは、設計方針を根本的に変更した。「S-Plan」と呼ばれる構造化疑似コードの導入と、既存のSui（S-IR）を下位の中間表現へと再定義する動きである2。

| 特徴 | 初期Sui（批判前） | 新Sui（ピボット後） |
| :---- | :---- | :---- |
| **主眼** | トークン効率、記号的簡潔さ | 決定論、検証可能性、修正容易性 |
| **LLM生成ターゲット** | 直接Suiコード（= v0 10） | **S-Plan**（構造化疑似コード） |
| **変数名** | 数値ID強制（v0, v1） | **意味のある識別子**（推論後にID化） |
| **エラー対策** | 構文の物理的制約 | 構造化出力（Schema）と検証 |
| **設計哲学** | 圧縮（Compression） | **分離（Decoupling）** |

この変更は、単なる機能追加ではなく、言語の存在意義を「生成の効率化」から「生成の信頼性担保」へと再定義するものである。本レポートでは、この転換がプログラミング言語として「役に立つ」ものになるか否かを、以下の観点から検証する。

1. **理論的妥当性：** セマンティクスとシンタックスの分離はLLMにとって本当に有益か？  
2. **実用的実現性：** Pythonの優位性を覆し、採用される余地はあるか？  
3. **設計の正誤：** 具体的な設計変更点における正解とリスクは何か？


**2\. 理論的枠組み：セマンティクスとシンタックスの分離**

ユーザーの問いにある「セマンティクス（意味）とシンタックス（表記）を分離した表現」は、今回のピボットにおける最も重要な技術的テーゼである。これがLLMにとっていかなるメリット・デメリットをもたらすかを理解するためには、LLMのコード生成プロセスを認知科学的に分解する必要がある。

### **2.1 生成AIにおける「結合」の問題点**

従来のプログラミング言語（例：Python, Java）において、意味と表記は密結合している。プログラマ（またはLLM）は、「リストの要素を合計する」という\*\*論理（セマンティクス）**を構築すると同時に、「インデントを揃える」「コロンを打つ」「括弧を閉じる」という**規則（シンタックス）\*\*を遵守しなければならない。

LLMにおいて、この二重の負荷はハルシネーションの温床となる。

* **構文的ハルシネーション:** 論理は正しいが、閉じ括弧を忘れてSyntax Errorになる。  
* **意味的ハルシネーション:** 文法は完璧だが、存在しないメソッドを呼び出す（例：リストに対して .push() を使うなど、言語ごとのAPIの混同）。

特に、LLMは確率的なトークン予測器であるため、文法的な制約（厳密なルール）と確率的な文脈（曖昧な意味）を同時に満たすことは、計算資源の競合を引き起こす。複雑なロジックを記述しようとすると文法が乱れ、文法に固執するとロジックが破綻するというトレードオフが発生しやすい。

### **2.2 「分離」のアプローチ：S-Planの役割**

Suiの新しい設計方針では、LLMの役割を「S-Plan（意味の記述）」に限定し、「S-IR（表記の解決）」をコンパイラ（決定論的プログラム）に委譲する。これは、ソフトウェア工学における「関心の分離（Separation of Concerns）」をLLM生成パイプラインに適用したものと言える。

**概念的な生成パイプライン：**

1. **ユーザー意図:** 「フィボナッチ数を計算したい」  
2. **LLM生成（S-Plan）:**  
   YAML  
   Function: Fibonacci  
   Args: n (integer)  
   Logic:  
     \- If n \< 2: Return n  
     \- Else: Return Fibonacci(n-1) \+ Fibonacci(n-2)

   *※ ここでは、メモリ管理やレジスタ割り当て（v0, v1）、具体的な構文（括弧やセミコロン）を気にする必要がない。*  
3. **決定論的変換（Compiler）:** S-Plan $\\to$ S-IR（従来のSuiコード \+ v0 v1 等） $\\to$ Wasm  
4. **実行:** WebAssemblyランタイム

このアーキテクチャは、最近の研究で注目されている「Chain of Code」3や「中間表現（IR）を用いた推論強化」4と強く共鳴する。LLMに直接最終的なコードを書かせるのではなく、抽象度の高い中間ステップを経由させることで、推論精度が向上することが示されている。


**3\. 「分離」のメリット・デメリット分析**

「セマンティクスとシンタックスの分離」がLLMにもたらす具体的な影響を、技術的な観点から詳細に分析する。

### **3.1 メリット（LLMにとっての有益性）**

#### **3.1.1 構文エラーの構造的排除（Structural Syntax Safety）**

最大のメリットは、構文エラーの完全な排除である。S-PlanがJSONやYAML、あるいはS式のような構造化データとして定義されている場合、OpenAIの「Structured Outputs」6や「Outlines」8のような制約付きデコーディング技術を利用できる。これにより、LLMは**定義されたスキーマに違反するトークンを出力することが物理的に不可能**になる。

* **従来:** 「構文エラーが出ないように祈りながらサンプリングする」  
* 分離後: 「構文エラーが存在し得ない空間でサンプリングする」  
  この信頼性の向上は、自動化されたエージェントループにおいて極めて重要である。

#### **3.1.2 認知負荷の軽減と推論リソースの集中（Cognitive Offloading）**

シンタックス（括弧やインデント）の生成から解放されることで、LLMはアテンションヘッドの容量を「論理の整合性」に集中できる。  
「S-Plan」のような疑似コード形式は、LLMの内部表現（思考の連鎖：Chain of Thought）に近い9。複雑なアルゴリズムを記述する際、Pythonの厳密な文法ルール（例えば、改行後のインデントレベルの維持）はノイズとなり得るが、S-Planのような抽象表現ではそのノイズが除去される。これにより、論理的な深さ（Depth of Reasoning）をより深く保つことが可能になる。

#### **3.1.3 修正の局所化（Differential Patching）**

ピボット後の方針に含まれる「差分修正（Patching）」2は、分離によって初めて実用的になる。  
密結合した言語（Python等）では、関数の一部を修正すると、インデントのズレや変数のスコープ（Global vs Local）の影響で、ファイル全体が壊れるリスクがある。しかし、セマンティクスが構造化されたツリー（S-Plan）として表現されていれば、LLMに対して「ノードID:45の条件分岐のみを反転せよ」という指示が可能になる。これは、コードの再生成ではなく、意味の外科手術を可能にし、トークンコストとエラー率を劇的に低下させる。

### **3.2 デメリット（懸念点とリスク）**

#### **3.2.1 「学習データの不在」による翻訳コスト（The Translation Gap）**

これが最大の懸念点である。LLM（GPT-4, Claude 3等）は、インターネット上の数十億行のPythonコードで学習している。彼らにとってPythonは「母国語」である。対して、S-Planは「未知の言語」である。

* **Few-Shotの限界:** S-Planを生成させるには、プロンプト内でその形式を定義し、例示（Few-Shot）する必要がある。LLMは未知の形式に対して、既知の形式（Python等）よりも推論性能が落ちる傾向がある10。  
* **翻訳の負荷:** ユーザーの自然言語指示をS-Planに変換するプロセスは、LLMにとって「翻訳作業」となる。母国語であるPythonで直接思考・出力する方が、結果的に高品質なコードが出る可能性（パラメトリックな知識の活用）が否定できない。

#### **3.2.2 韻律情報の欠落（Loss of Prosody）**

コードのシンタックス（特にPythonのインデントや空行）は、単なる記号ではなく、意味のまとまりや「リズム」を伝える情報を含んでいる。これを「韻律（Prosody）」と呼ぶ。  
S-Planのような純粋な意味表現（例えばJSONツリー）に過度に正規化してしまうと、コードが持つ視覚的な構造情報が失われる。研究4によれば、AST（抽象構文木）を直接LLMに読ませても、人間が書いたソースコードほど理解できない場合がある。シンタックスが持つ「冗長性」は、実はLLMが文脈を理解するためのヒントになっているのである。

#### **3.2.3 デバッグの複雑化（The Source Map Problem）**

セマンティクス（S-Plan）と実行コード（S-IR/Wasm）が分離されると、実行時エラーの解決が困難になる。  
Wasmレベルで発生した「メモリ境界外アクセス」のエラーを、どうやってLLMが理解できるS-Planのレベルまで逆翻訳して提示するか？ この「逆写像（Source Mapping）」の仕組みが不十分だと、LLMは「自分が書いたつもりがないコードのエラー」を修正させられることになり、修正ループが破綻する。


**4\. 設計方針の評価：正誤の判定**

Suiの方針変更について、具体的にどの点が「正しい（合理的）」で、どの点が「正しくない（リスクが高い）」かを、理由とともに判定する。

### **4.1 正しいと判断される設計方針**

#### **4.1.1 トークン効率至上主義の放棄（Rejection of Token Efficiency）**

判定: 妥当  
理由: LLMのコンテキストウィンドウは拡大傾向（128k〜1Mトークン）にあり、数トークンを節約するために可読性を犠牲にする初期設計は時代遅れであった。v0 を user\_count に戻すという決定2は、TransformerのAttention機構が意味的類似性（Semantic Similarity）に依存していることを踏まえると、極めて正しい。意味のある変数名は、コードの品質を担保する最大のメタデータである。

#### **4.1.2 決定論的実行へのフォーカス（Focus on Deterministic Execution）**

判定: 妥当  
理由: Python等の動的言語は、実行環境（ライブラリのバージョン、OSの違い）によって挙動が変わる非決定論的な要素を持つ。AIエージェントが自律的にコードを実行する際、この不確実性は致命的となる。Suiが「同じS-Planからは常に同じバイナリが生成され、同じ結果になる」ことを保証できれば、AIエージェントのためのサンドボックスとして独自の地位を築ける。

#### **4.1.3 S-Planにおける「構造化疑似コード」の採用**

判定: 妥当  
理由: SudoLang12やHoPC9の成功事例が示すように、LLMは自然言語とコードの中間的な表現（疑似コード）において高い推論能力を発揮する。S-Planを「ガチガチのAST」ではなく「構造化された疑似コード」として設計する方向性は、LLMの特性に合致している。

### **4.2 正しくない、または懸念が残る設計方針**

#### **4.2.1 独自IRとしてのSui記法の維持**

判定: 疑問  
理由: 批判への対応として、従来のSui記法（= v0 10）を「内部IR」として残すとしている2。しかし、LLMが直接生成しないのであれば、なぜWebAssembly Text Format (WAT) やLLVM IRといった既存の標準的なIRを採用しないのか？ 独自のIRを維持することは、コンパイラやデバッガのエコシステムを全て自前で整備し続けることを意味する。これは「車輪の再発明」であり、プロジェクトのリソースを浪費するリスクが高い。

#### **4.2.2 「標準ライブラリ」の不足と孤立**

判定: リスク大  
理由: LLMがPythonを好む最大の理由は、pandas や requests といった強力なライブラリのエコシステムがあるからである。Suiが「純粋論理言語」13であることを強調すればするほど、実世界との接点（API通信、ファイル操作）が失われる。LLMにとって、外部ツールを使えない言語は「考えること」しかできず、「仕事をすること」ができない。S-PlanからPythonのライブラリを呼び出すようなFFI（Foreign Function Interface）の構想が見えない限り、実用性は極めて限定的になる。

#### **4.2.3 学習データ不足への対策の欠如**

判定: 重大な欠落  
理由: S-Planがいかに優れたフォーマットであっても、GPT-5やClaude 4の学習データに含まれていなければ、LLMはその書き方を知らない。ピボット後の方針には「S-PlanをどうやってLLMに教えるか」という戦略（ファインチューニング用データセットの公開や、システムプロンプトの設計）が具体的に示されていない。ここが解決されなければ、Suiは「理論上最強の言語」で終わる可能性がある。


**5\. Suiはプログラミング言語として「役に立つ」ものになるか？**

この問いに対する結論を導くために、Suiが競合する既存のソリューション（Python \+ Linter/Agentic Frameworks）と比較検討する。

### **5.1 比較分析：Sui vs Pythonエコシステム**

| 評価軸 | Python (現状の覇者) | Sui (ピボット後の理想像) |
| :---- | :---- | :---- |
| **学習データ量** | 圧倒的 (数十億行) | ほぼゼロ (Few-shot頼み) |
| **エコシステム** | 巨大 (PyPI) | 未整備 |
| **実行の安全性** | 低 (サンドボックス必須) | **高 (Wasmによる隔離)** |
| **構文エラー率** | 低〜中 (LLMの能力に依存) | **ゼロ (構造化出力による保証)** |
| **デバッグ** | 容易 (人間が読める) | 困難 (IRとS-Planの乖離) |
| **用途** | 汎用 (Web, AI, Data) | **特化 (ロジック検証, 安全な実行)** |

### **5.2 「役に立つ」ための条件とシナリオ**

Suiが汎用的なプログラミング言語としてPythonに取って代わる可能性は、現時点では極めて低い。LLMの「母国語」であるPythonの地位は揺るぎない。  
しかし、特定のニッチな領域、特に\*\*「高信頼性エージェント（High-Reliability Agents）」\*\*のバックエンドとしては、極めて有用になる可能性がある。

#### **シナリオ：自律型AIエージェントの安全装置**

金融取引やインフラ制御など、ミスが許されない領域でAIエージェントを動かす場合、Pythonの柔軟性はリスクとなる（意図しないライブラリのインポートや無限ループなど）。  
Suiが以下の機能を提供できれば、実用的な価値が生まれる：

1. **Strict Sandbox:** S-Planで記述されたロジックが、許可されたリソース以外に絶対にアクセスできないことをコンパイラレベルで保証する。  
2. **Verifiable Logic:** S-Planが形式手法（Formal Methods）と連携し、コード生成時に「矛盾がないこと」を数学的に証明できる14。  
3. **Cross-Platform:** 生成されたS-IRがWasmとして、ブラウザ、サーバー、エッジデバイスのどこでも安全に動く。

この場合、Suiは「人間が書く言語」ではなく、「**AIエージェントが安全に思考し、実行するための専用プロトコル**」として再定義される。これこそが、Suiが生き残る唯一の道であると考えられる。


**6\. 結論と提言**

### **6.1 総括**

Suiの方針変更は、初期のナイーブな「トークン削減」アプローチからの脱却として高く評価できる。特に「セマンティクスとシンタックスの分離」は、LLMのハルシネーションを構造的に抑制し、決定論的な動作を保証するための理論的に正しいアプローチである。  
しかし、現状のままでは「学習データの不在」と「ライブラリの欠如」という高い壁に阻まれ、実用化には至らないリスクが高い。

### **6.2 提言**

Suiが真に「LLMにやさしく、役に立つ言語」になるためには、以下の戦略的修正が必要である。

1. **S-Planの標準化と公開:** S-PlanをSui専用の内部フォーマットにするのではなく、\*\*「LLMのための標準疑似コード仕様（Standard Agentic Interface）」\*\*として定義し、JSON Schema等を公開する。これにより、他のエージェントフレームワーク（LangChain等）からの採用を促す。  
2. **Pythonバインディングの強化:** 「純粋な論理」に固執せず、ホスト環境（Python/JS）の関数をS-Planから安全に呼び出せるFFIを第一級市民としてサポートする。これにより、実用的なタスク（APIコール等）が可能になる。  
3. **独自IRの隠蔽または廃止:** 開発リソースを独自IR（旧Sui）の維持ではなく、S-PlanからWasmへの最適化コンパイラ、およびデバッグ支援ツール（S-Plan上でのステップ実行など）に集中させる。

最終結論:  
この変更によって、Suiは「おもちゃの言語」から「次世代のAIインフラストラクチャの候補」へと進化するポテンシャルを得た。しかし、それが「役に立つ」ものになるかどうかは、言語仕様の美しさではなく、「LLMがいかに自然にS-Planを生成できるか」という学習/プロンプトエンジニアリングの側面と、「生成されたコードが現実世界といかに連携できるか」というランタイムの側面にかかっている。現時点では「有望だが、実用化へのハードルは依然として高い」と評価するのが妥当である。

#### **引用文献**

1. README.md \- TakatoHonda/sui-lang \- GitHub, 12月 13, 2025にアクセス、 [https://github.com/TakatoHonda/sui-lang/blob/main/README.md](https://github.com/TakatoHonda/sui-lang/blob/main/README.md)  
2. 「LLMにやさしい言語SuiはLLMにやさしくなれそう」｜本田崇人 ..., 12月 13, 2025にアクセス、 [https://note.com/t\_honda/n/n7822eccdfca1](https://note.com/t_honda/n/n7822eccdfca1)  
3. Code Reasoning Techniques \- Emergent Mind, 12月 13, 2025にアクセス、 [https://www.emergentmind.com/topics/code-reasoning-techniques](https://www.emergentmind.com/topics/code-reasoning-techniques)  
4. NL in the Middle: Code Translation with LLMs and Intermediate Representations \- arXiv, 12月 13, 2025にアクセス、 [https://arxiv.org/html/2507.08627v2](https://arxiv.org/html/2507.08627v2)  
5. For Peer Review \- Stanford University, 12月 13, 2025にアクセス、 [https://web.stanford.edu/\~zhangxm/Towards\_Exception\_Safety\_Code\_Generation\_with\_Intermediate\_Representation\_Agents\_Framework.pdf](https://web.stanford.edu/~zhangxm/Towards_Exception_Safety_Code_Generation_with_Intermediate_Representation_Agents_Framework.pdf)  
6. 12月 13, 2025にアクセス、 [https://humanloop.com/blog/structured-outputs\#:\~:text=Structured%20outputs%20ensure%20model%20responses,consistent%2C%20machine%2Dreadable%20data.](https://humanloop.com/blog/structured-outputs#:~:text=Structured%20outputs%20ensure%20model%20responses,consistent%2C%20machine%2Dreadable%20data.)  
7. Structured Outputs: Everything You Should Know \- Humanloop, 12月 13, 2025にアクセス、 [https://humanloop.com/blog/structured-outputs](https://humanloop.com/blog/structured-outputs)  
8. Taming LLMs: How to Get Structured Output Every Time (Even for Big Responses), 12月 13, 2025にアクセス、 [https://dev.to/shrsv/taming-llms-how-to-get-structured-output-every-time-even-for-big-responses-445c](https://dev.to/shrsv/taming-llms-how-to-get-structured-output-every-time-even-for-big-responses-445c)  
9. Hint of Pseudo Code (HoPC): Zero-Shot Step by Step Pseudo Code Reasoning Prompting \- arXiv, 12月 13, 2025にアクセス、 [https://arxiv.org/html/2305.11461v8](https://arxiv.org/html/2305.11461v8)  
10. TLDR: I've tested 17 LLMs against 4 typed programming languages to see which excels at what., 12月 13, 2025にアクセス、 [https://terhech.de/posts/2025-01-31-llms-vs-programming-languages.html](https://terhech.de/posts/2025-01-31-llms-vs-programming-languages.html)  
11. IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators \- ACL Anthology, 12月 13, 2025にアクセス、 [https://aclanthology.org/2024.acl-long.802.pdf](https://aclanthology.org/2024.acl-long.802.pdf)  
12. SudoLang LLM Support for VSCode \- GitHub, 12月 13, 2025にアクセス、 [https://github.com/paralleldrive/sudolang-llm-support](https://github.com/paralleldrive/sudolang-llm-support)  
13. TakatoHonda/sui-lang: 粋 (Sui) \- A programming language ... \- GitHub, 12月 13, 2025にアクセス、 [https://github.com/TakatoHonda/sui-lang](https://github.com/TakatoHonda/sui-lang)  
14. Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference \- ResearchGate, 12月 13, 2025にアクセス、 [https://www.researchgate.net/publication/389694437\_Can\_LLMs\_Reason\_About\_Program\_Semantics\_A\_Comprehensive\_Evaluation\_of\_LLMs\_on\_Formal\_Specification\_Inference](https://www.researchgate.net/publication/389694437_Can_LLMs_Reason_About_Program_Semantics_A_Comprehensive_Evaluation_of_LLMs_on_Formal_Specification_Inference)

---

## Geminiの見解を受けて

結局、Suiが普及するにはLLMがSuiを学習するための大量のコード(Pythonで数十億行)が必要であり、大量の学習コードを得るにはSuiが普及しないといけないという、[キャッチ=22](https://ja.wikipedia.org/wiki/%E3%82%AD%E3%83%A3%E3%83%83%E3%83%81%3D22)の状況に陥っているんですね。

あと、やっぱりなと思ったのが、

> コードのシンタックス（特にPythonのインデントや空行）は、単なる記号ではなく、意味のまとまりや「リズム」を伝える情報を含んでいる。これを「韻律（Prosody）」と呼ぶ。

というように、シンタックスも大事なんだな、という点です。

 > 研究4によれば、AST（抽象構文木）を直接LLMに読ませても、人間が書いたソースコードほど理解できない場合がある。

 データ・サイエンティストだから、コンパイラとLLMの関係の論文調査はしていないのかな。

 まあ、人類を愚か者呼ばわりする人は、自分も愚か者の人類なのだと自覚してLLMにお伺いを立ててから行動した方が良いのかも…

 **おまけ**

「再度、評価してもらう」と書いたのは、[こちら](https://note.com/liptpn/n/nee6fa498a074)で方針変更前の評価があるからです。ホント、凄い時代になったものです。
 